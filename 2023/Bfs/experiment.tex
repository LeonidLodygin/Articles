% !TeX spellcheck = ru_RU
% !TEX root = bfs_lodygin.tex

\section{Эксперимент}

В данном разделе предлагается рассмотреть результаты экспериментального исследования реализованного алгоритма обхода графа в ширину. Основная задача: выявить зависимость производительности алгоритма от входных параметров графа и количества асинхронных потоков, обрабатывающих данный алгоритм.

\subsection{Условия эксперимента}
Для экспериментов использовалась рабочая станция с процессором Intel Core i5-10300H с тактовой частотой 2.50GHz, RAM DDR4 объемом 8гб под управлением OC Windows 10 Pro версии 21H2.

\subsection{Исследовательские вопросы }

\begin{itemize}
\item[\textbf{RQ1:}] При каких параметрах графа выгоднее использовать параллельную версию алгоритма, а при каких последовательную?
\item[\textbf{RQ2:}] Использование какого количества потоков даёт наибольший выигрыш в производительности и почему?
\end{itemize}


\subsection{Метрики}
В качестве метрик производительности используется время, требуемое на завершение алгоритма. Показатели времени получены с помощью библиотеки \texttt{BenchmarkDotNet v0.13.5}\footnote{\url{https://github.com/dotnet/BenchmarkDotNet} (дата доступа:   \DTMdate{2023-05-21}).}.

Для анализа алгоритма было решено воспользоваться собственным генератором графов нужного размера с нужной плотностью. Данный подход позволяет минимизировать влияние разницы прочих параметров на исследуемый, следовательно результаты, полученные в таком исследовании, позволят точнее выявить необходимые зависимости, нежели при подборе базы графов из реальных существующих. Генератор принимает на вход количество вершин в графе и параметр \texttt{density} типа \texttt{float}, отвечающий за плотность графа. По заданным вершинам создается двумерный массив, заполненный либо \texttt{Option.None}, если плотность графа менее $50\%$, либо случайным числом типа \texttt{int}, обёрнутым в тип \texttt{Option}. По параметру плотности графа вычисляется количество рёбер, необходимое для достижения такой плотности.
Затем, запускается цикл, в котором генерируются два числа от нуля до количества вершин и, в зависимости от того, является граф плотным или нет, ячейки массива, соответствующие сгенерированным числам, заполняются либо случайными числами типа \texttt{int}, обёрнутым в тип \texttt{Option}, либо \texttt{Option.None}.  


\subsection{Результаты}

Входные параметры:
 \begin{enumerate}
 \item  \texttt{Vertices} --- количество вершин в графе; 
 \item  \texttt{Density} --- плотность графа;
 \item \texttt{parallelMult} --- уровень распараллеливания функции умножения, каждый уровень увеличивает число потоков в 2 раза;
  \item \texttt{parallelAdd} --- уровень распараллеливания функции сложения, каждый уровень увеличивает число потоков в 2 раза.
\end{enumerate}

Результаты замеров:
\begin{enumerate}
\item  \texttt{Time} --- результат измерений в мс ( за исключением таблицы~\ref{bfscomparison}, где вермя измерений указано в микросекундах и таблицы~\ref{bfsmaxgraph}, где время указано в секундах);
\item  \texttt{Error} --- погрешность измерений в мс.
\end{enumerate}

Замеры проводились начиная от сравнительно малых графов (500 вершин), заканчивая графами с 5000 вершинами. Выбор максимального размера графа связан с ограничением оперативной памяти системы, на которой производились вычисления.

В таблице~\ref{bfs0} представлены результаты замеров времени работы последовательного алгоритма при различных входных параметрах графа. Из данной таблицы видно, что время работы алгоритма возрастает с увеличением плотности графа, а затем, когда граф достигает плотности $0.7$ начинает снижаться. Не трудно догадаться, что при высокой плотности графа уменьшается количество шагов алгоритма, необходимых для его завершения, так как за каждый шаг будет осуществляться переход в большее количество смежных вершин, следовательно общее время работы уменьшается.

\begin{table}[h]
\centering
    \caption{Производительность последовательного алгоритма обхода графов в ширину.}
    \scalebox{0.7}{
    \begin{tabular}{| a | r | r | r | a | r | r | r |}
    \toprule
        \multicolumn{1}{|c|}{\textsc{Vertices}} & \multicolumn{1}{c|}{\textsc{Density}} & \multicolumn{1}{c|}{\textsc{Time}} &
        \multicolumn{1}{c|}{\textsc{Error}} & \multicolumn{1}{c|}{\textsc{Vertices}} & \multicolumn{1}{c|}{\textsc{Density}} & \multicolumn{1}{c|}{\textsc{Time}} &
        \multicolumn{1}{c|}{\textsc{Error}} \\ \midrule
        \rowcolor{gray}500 & 0.1 & 17 & 0.06 & 2500 & 0.1 & 429 & 1.7  \\ \midrule
        500 & 0.3 & 33 & 0.3 & 2500 & 0.3 & 860 & 3.4 \\ \midrule
        \rowcolor{gray}500 & 0.7 & 42 & 0.2 & 2500 & 0.7 & 1095 & 3.0  \\ \midrule
        500 & 0.9 & 36 & 0.17 & 2500 & 0.9 & 980 & 4.0  \\ \midrule
        
        \rowcolor{gray}1000 & 0.1 & 68 & 0.4 & 5000 & 0.1 & 1717 & 3 \\ \midrule
        1000 & 0.3 & 137 & 0.6 & 5000 & 0.3 & 3531 & 20 \\ \midrule
        \rowcolor{gray}1000 & 0.7 & 179 & 1.2 & 5000 & 0.7 & 4421 & 9 \\ \midrule
        1000 & 0.9 & 158 & 0.3 & 5000 & 0.9 & 3984 & 14 \\ \bottomrule 
    \end{tabular}%
    }
    \label{bfs0}
\end{table}

В таблице~\ref{bfsparallel} приведены результаты замеров времени работы параллельного алгоритма обхода графа при различных параметрах. Для удобства, при каждом параметре плотности графа взята наилучшая скорость среди всех параллельных версий алгоритма. Из полученных результатов можно заметить, что при увеличении размеров графа, наиболее оптимальное количество потоков для параллельных вычислений выравнивается к 4 для функции умножения. Стоить отметить, что на достаточно больших графах, при одном и том же уровне распараллеливания функции умножения, влияние распараллеливания функции сложения становится не столь существенным, любая из комбинаций даёт один и тот же результат по времени в пределах погрешности. Связано это с тем, что наибольший процент времени выделяется под функцию умножения, как наиболее затратную по ресурсам.

\begin{table}[h]
\centering
    \caption{Производительность параллельного алгоритма обхода графов в ширину (лучшие данные по метрике).}
    \scalebox{0.5}{
    \begin{tabular}{| a | r | r | r | r | r | a | r | r | r | r | r |}
    \toprule
        \multicolumn{1}{|c|}{\textsc{Vertices}} & \multicolumn{1}{c|}{\textsc{Density}} & \multicolumn{1}{c|}{\textsc{parallelMult}} & \multicolumn{1}{c|}{\textsc{parallelAdd}} & \multicolumn{1}{c|}{\textsc{Time}} &
        \multicolumn{1}{c|}{\textsc{Error}} & \multicolumn{1}{c|}{\textsc{Vertices}} & \multicolumn{1}{c|}{\textsc{Density}} & \multicolumn{1}{c|}{\textsc{parallelMult}} & \multicolumn{1}{c|}{\textsc{parallelAdd}} & \multicolumn{1}{c|}{\textsc{Time}} &
        \multicolumn{1}{c|}{\textsc{Error}} \\ \midrule
        \rowcolor{gray}500 & 0.1 & 2 & 1 & 9.4 & 0.2 & 2500 & 0.1 & 2 & 3 & 241 & 5  \\ \midrule
        500 & 0.3 & 1 & 1 & 19.3 & 0.17 & 2500 & 0.3 & 2 & 3 & 464 & 9 \\ \midrule
         \rowcolor{gray}500 & 0.7 & 1 & 2 & 26 & 0.2 & 2500 & 0.7 & 2 & 3 & 650 & 11  \\ \midrule
        500 & 0.9 & 2 & 2 & 23 & 0.3 & 2500 & 0.9 & 2 & 1 & 585 & 12  \\ \midrule
        
        \rowcolor{gray}1000 & 0.1 & 1 & 1 & 37 & 0.7 & 5000 & 0.1 & 2 & 1 & 970 & 19 \\ \midrule
        1000 & 0.3 & 1 & 1 & 73 & 0.9 & 5000 & 0.3 & 2 & 3 & 1814 & 36 \\ \midrule
        \rowcolor{gray}1000 & 0.7 & 1 & 2 & 99 & 1.4 & 5000 & 0.7 & 2 & 3 & 2606 & 51 \\ \midrule
        1000 & 0.9 & 1 & 3 & 91 & 1.5 & 5000 & 0.9 & 2 & 1 & 2326 & 45 \\ \bottomrule 
    \end{tabular}%
    }
    \label{bfsparallel}
\end{table}

Для более точного анализа были произведены дополнительные замеры при очень малых размерах входного графа (таблица~\ref{bfscomparison}). Выяснилось, что при малых размерах графа последовательная версия работает значительно быстрее, чем параллельная.

\begin{table}[h]
\centering
    \caption{Сравнение производительности параллельного и обычного Bfs на графах с малым количеством вершин.}
    \scalebox{0.7}{
    \begin{tabular}{| a | r | r | r | a | r | r | r |}
    \toprule
        \multicolumn{1}{|c|}{\textsc{Vertices}} & \multicolumn{1}{c|}{\textsc{Density}} & \multicolumn{1}{c|}{\textsc{TimeBfs}} &
        \multicolumn{1}{c|}{\textsc{Error}} & \multicolumn{1}{c|}{\textsc{Vertices}} & \multicolumn{1}{c|}{\textsc{Density}} & \multicolumn{1}{c|}{\textsc{TimeParallelBfs}} &
        \multicolumn{1}{c|}{\textsc{Error}} \\ \midrule
        \rowcolor{gray}10 & 0.1 & 15 & 0.03 & 10 & 0.1 & 53 & 0.2  \\ \midrule
        10 & 0.3 & 20 & 0.4 & 10 & 0.3 & 78 & 0.3 \\ \midrule
        \rowcolor{gray}10 & 0.7 & 27 & 0.5 & 10 & 0.7 & 60 & 0.4  \\ \midrule
        10 & 0.9 & 25 & 0.6 & 10 & 0.9 & 44 & 0.4  \\ \bottomrule 
    \end{tabular}%
    }
    \label{bfscomparison}
\end{table}

Аналогично, чтобы исследовать оптимальное разделение потоков для функции умножения, были проведены замеры с теми же размерами и плотностями графа, но с использованием последовательной функции сложения. Результаты приведены в таблице~\ref{bfsparallelmult}.

\begin{table}[h]
\centering
    \caption{Производительность параллельного алгоритма обхода графов в ширину с использованием последовательной функции сложения веторов.}
    \scalebox{0.6}{
    \begin{tabular}{| a | r | r | r | r | a | r | r | r | r |}
    \toprule
        \multicolumn{1}{|c|}{\textsc{Vertices}} & \multicolumn{1}{c|}{\textsc{Density}} & \multicolumn{1}{c|}{\textsc{parallelMult}} & \multicolumn{1}{c|}{\textsc{Time}} &
        \multicolumn{1}{c|}{\textsc{Error}} & \multicolumn{1}{c|}{\textsc{Vertices}} & \multicolumn{1}{c|}{\textsc{Density}} & \multicolumn{1}{c|}{\textsc{parallelMult}} & \multicolumn{1}{c|}{\textsc{Time}} &
        \multicolumn{1}{c|}{\textsc{Error}} \\ \midrule
        \rowcolor{gray}500 & 0.1 & 1 & 9,8 & 0.1 & 2500 & 0.1 & 2 & 240 & 3  \\ \midrule
        500 & 0.3 & 1 & 19 & 0.4 & 2500 & 0.3 & 2 & 470 & 9 \\ \midrule
        \rowcolor{gray}500 & 0.7 & 1 & 26 & 0.5 & 2500 & 0.7 & 2 & 661 & 13  \\ \midrule
        500 & 0.9 & 2 & 24 & 0.4 & 2500 & 0.9 & 2 & 620 & 12  \\ \midrule
        
        \rowcolor{gray}1000 & 0.1 & 1 & 36 & 0.5 & 5000 & 0.1 & 2 & 923 & 18 \\ \midrule
        1000 & 0.3  & 1 & 72 & 1.4 & 5000 & 0.3 & 2 & 1843 & 36 \\ \midrule
        \rowcolor{gray}1000 & 0.7 & 1 & 98 & 1.6 & 5000 & 0.7 & 2 & 2571 & 39 \\ \midrule
        1000 & 0.9 & 1 & 90 & 1.1 & 5000 & 0.9 & 2 & 2372 & 41 \\ \bottomrule 
    \end{tabular}%
    }
    \label{bfsparallelmult}
\end{table}

В ходе замеров было установлено, что при увеличении размеров графа, вне зависимости от плотности, время работы алгоритма на 8 потоках для функции умножения хоть и больше, чем при работе на 4 потоках, но разрыв становится все меньше и меньше. Вследствие этого наблюдения, было решено произвести замеры для параллельных версий алгоритма для графов гораздо большего размера, но маленькой плотности с целью выяснить, сможет ли восьмипоточная версия обогнать по производительности четырёхпоточную. Результаты приведены в таблице~\ref{bfsmaxgraph}.

\begin{table}[h]
\centering
    \caption{Сравнение производительности алгоритма обхода в ширину при использовании 4 и 8 потоков для функции умножения.}
    \scalebox{0.6}{
    \begin{tabular}{| a | r | r | r | r |}
    \toprule
        \multicolumn{1}{|c|}{\textsc{Vertices}} & \multicolumn{1}{c|}{\textsc{Density}} & \multicolumn{1}{c|}{\textsc{parallelMult}} & \multicolumn{1}{c|}{\textsc{Time}} &
        \multicolumn{1}{c|}{\textsc{Error}} \\ \midrule
        \rowcolor{gray}2500 & 0.1 & 2 & 0.24 & 0.002 \\ \midrule
        2500 & 0.1 & 3 & 0.3 & 0.004 \\ \midrule
        \rowcolor{gray}5000 & 0.1 & 2 & 0.924 & 0.03 \\ \midrule
        5000 & 0.1 & 3 & 1.15 & 0.03 \\ \midrule
        \rowcolor{gray}10000 & 0.1 & 2 & 3.8 & 0.07 \\ \midrule
        10000 & 0.1 & 3 & 4.8 & 0.11 \\ \bottomrule 
    \end{tabular}%
    }
    \label{bfsmaxgraph}
\end{table}

Однако, как показало дополнительное измерение при графе с 10000 вершинами, по производительности всё так же лидирует распараллеливание на 4 потока, причём разрыв между скоростями вырос.

\subsubsection{RQ1} Исходя из полученных данных, последовательная версия алгоритма работает быстрее параллельной только на очень малых графах, когда накладные расходы на выделение дополнительных потоков и их синхронизацию влияют сильнее, чем ускорение относительно последовательной версии. При входных графах от 100 вершин и более, параллельная версия даёт внушительный прирост к производительности при любых параметрах плотности.
\subsubsection{RQ2} В ходе экспериментов было установлено, что использование 4 потоков, начиная с определённых размеров графа, даёт максимальный прирост по производительности алгоритма обхода в ширину. Такой результат можно объяснить количеством ядер процессора. Система, на которой производились замеры имеет 4-х ядерный процессор \texttt{Intel Core i5-10300H}, вследствие чего количество независимых вычислителей равняется четырём. С другой стороны, данный процессор поддерживает технологию \texttt{Hyper-Threading}, позволяющую разделить одно ядро процессора на 2 отдельных логических процессора, работающих независимо. Таким образом наилучшая производительность должная была наблюдаться на 8 потоках. Причиной несоответствия реальной картины картине теоретической может служить наличие другого компонента, который становится \enquote{узким} местом в системе, например, оперативная память.
